{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "from Model_DADSSFF import DADSSFF\n",
    "import torch.nn.functional as F \n",
    "from GeneratePic import generate_png\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn import metrics, preprocessing\n",
    "from Gain_batch import gain_train_test_batch, gain_total_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Hyerparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='CD-DADSSFF')\n",
    "parser.add_argument('--dataset',              default='USA', help ='name   of datasets: China, River, USA')\n",
    "parser.add_argument('--patches',  type=int,   default=7,       help ='size   of patches')\n",
    "parser.add_argument('--batches',  type=int,   default=64,      help ='number of batches')\n",
    "parser.add_argument('--epoches',  type=int,   default=100,     help ='amount of epoches')\n",
    "parser.add_argument('--tr_rate',  type=float, default=5e-2,    help ='rate   of train')\n",
    "parser.add_argument('--lr_rate',  type=float, default=0.001,   help ='rate   of learning')\n",
    "parser.add_argument('--decay',    type=float, default=0.001,   help ='weight of decay ')\n",
    "parser.add_argument('--cuda',     type=int,   default=2,       help ='ID     of cuda ')\n",
    "parser.add_argument('--seed',     type=int,   default=1024,    help ='random seed ')\n",
    "\n",
    "parser.add_argument('--lambdas1', type=float, default=0.5,     help ='Hyperparameter of DA  loss')\n",
    "parser.add_argument('--lambdas2', type=float, default=0.4,     help ='Hyperparameter of KLD loss')\n",
    "\n",
    "args=parser.parse_args(args=[])\n",
    "\n",
    "Device = torch.device('cuda:' + str(args.cuda) if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_T1.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/Pytorch/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_T1.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     GT \u001b[38;5;241m=\u001b[39m sio\u001b[38;5;241m.\u001b[39mloadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/qinxuexiang/01_ChangeDetection/data/02_River/River_GT.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRiver_GT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSA\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 10\u001b[0m     T1 \u001b[38;5;241m=\u001b[39m \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_T1.mat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSA_T1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m     T2 \u001b[38;5;241m=\u001b[39m sio\u001b[38;5;241m.\u001b[39mloadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_T2.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSA_T2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m     GT \u001b[38;5;241m=\u001b[39m sio\u001b[38;5;241m.\u001b[39mloadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_GT.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSA_GT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/Pytorch/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:225\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m~/anaconda3/envs/Pytorch/lib/python3.9/contextlib.py:117\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Pytorch/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[0;32m~/anaconda3/envs/Pytorch/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_T1.mat'"
     ]
    }
   ],
   "source": [
    "if args.dataset == 'China':\n",
    "    T1 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/code/DADSSFF/data/01_China/China_T1.mat')['China_T1']\n",
    "    T2 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/code/DADSSFF/data/01_China/China_T2.mat')['China_T2']\n",
    "    GT = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/code/DADSSFF/data/01_China/China_GT.mat')['China_GT']\n",
    "elif args.dataset == 'River':\n",
    "    T1 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/02_River/River_T1.mat')['River_T1']\n",
    "    T2 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/02_River/River_T2.mat')['River_T2']\n",
    "    GT = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/02_River/River_GT.mat')['River_GT']\n",
    "elif args.dataset == 'USA':\n",
    "    T1 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_T1.mat')['USA_T1']\n",
    "    T2 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_T2.mat')['USA_T2']\n",
    "    GT = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_GT.mat')['USA_GT']\n",
    "else:\n",
    "    print(\"Please enter one of 'China', 'River' and 'USA'!\")\n",
    "\n",
    "H1, W1, B1=T1.shape\n",
    "H2, W2, B2=T2.shape\n",
    "TT1=T1.reshape(H1*W1, B1)\n",
    "TT2=T2.reshape(H2*W2, B2)\n",
    "T1=preprocessing.scale(TT1)\n",
    "T2=preprocessing.scale(TT2)\n",
    "Time1=T1.reshape(H1, W1, B1)\n",
    "Time2=T2.reshape(H2, W2, B2)\n",
    "classes_num=np.max(GT)+1\n",
    "print(\"Time1 shape: \", Time1.shape)\n",
    "print(\"Time2 shape: \", Time2.shape)\n",
    "print('class_num:',    classes_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_loader, Test_loader = gain_train_test_batch(Time1, Time2, GT, args.tr_rate, args.patches, args.batches, args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DADSSFF(bands=B1, num_classes=classes_num).to(Device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr_rate, weight_decay=args.decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0\n",
    "for epoch in range(args.epoches):\n",
    "    model.train()\n",
    "    Train_Loss, Train_GT, Train_label= [], [], []\n",
    "\n",
    "    for train_T1, train_T2, train_gt in Train_loader:\n",
    "\n",
    "        train_T1, train_T2, train_gt = train_T1.to(Device), train_T2.to(Device), train_gt.to(Device)\n",
    "\n",
    "        ## 1) Forwards\n",
    "        train_pred, train_DA_loss, train_KLD_loss = model(train_T1, train_T2)\n",
    "        loss = criterion(train_pred, train_gt) + args.lambdas1*train_DA_loss + args.lambdas2*train_KLD_loss\n",
    "\n",
    "        ## 2) Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ## 3) Backward and update weights\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        ## 4) estimate accuracy\n",
    "        _, train_label = torch.max(F.softmax(train_pred, dim=1), 1)\n",
    "\n",
    "        Train_Loss.append(loss.cpu().item())\n",
    "        Train_GT.extend(np.array(train_gt.cpu()))\n",
    "        Train_label.extend(np.array(train_label.cpu()))\n",
    "\n",
    "    Train_Loss = np.array(Train_Loss)\n",
    "    Train_GT   = np.array(Train_GT)\n",
    "    Train_label= np.array(Train_label)\n",
    "    Train_F1   = metrics.f1_score(Train_GT, Train_label)\n",
    "\n",
    "    ## Test\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        model.eval()    \n",
    "        with torch.no_grad():\n",
    "\n",
    "            Test_loss, Test_GT, Test_label = [], [], []\n",
    "                      \n",
    "            for test_T1, test_T2, test_gt in Test_loader:\n",
    "\n",
    "                test_T1, test_T2, test_gt = test_T1.to(Device), test_T2.to(Device), test_gt.to(Device)\n",
    "\n",
    "                test_pred, test_DA_loss, test_KLD_loss = model(test_T1, test_T2) \n",
    "                test_loss = criterion(test_pred, test_gt) + args.lambdas1*test_DA_loss + args.lambdas2*test_KLD_loss\n",
    "\n",
    "                _, test_label = torch.max(F.softmax(test_pred, dim=1), 1)\n",
    "\n",
    "                Test_loss.append(test_loss.cpu().item())\n",
    "                Test_GT.extend(np.array(test_gt.cpu()))\n",
    "                Test_label.extend(np.array(test_label.cpu()))\n",
    "\n",
    "        Test_loss = np.array(Test_loss)\n",
    "        Test_GT   = np.array(Test_GT)\n",
    "        Test_label= np.array(Test_label)\n",
    "        Test_F1   = metrics.f1_score(Test_GT,Test_label)\n",
    "\n",
    "        print('epoch: {:03d}/{}; Train loss: {:.4f}; Train F1: {:.4f}; // Test loss:{:.4f}; Test F1: {:.4f}'.format\\\n",
    "              (epoch+1, args.epoches, np.mean(Train_Loss), Train_F1*100, np.mean(Test_loss), Test_F1*100))\n",
    "\n",
    "        if Test_F1 >= best:\n",
    "            best = Test_F1\n",
    "            name='DADSSFF_' + args.dataset + '.pth'\n",
    "            torch.save(model, name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='DADSSFF_' + args.dataset + '.pth'\n",
    "model = torch.load(name)\n",
    "model.eval()    \n",
    "with torch.no_grad():\n",
    "\n",
    "    Test_GT, Test_label = [], []\n",
    "                      \n",
    "    for test_T1, test_T2, test_gt in Test_loader:\n",
    "\n",
    "        test_T1, test_T2, test_gt = test_T1.to(Device), test_T2.to(Device), test_gt.to(Device)\n",
    "\n",
    "        test_pred, _, _ = model(test_T1, test_T2)        \n",
    "\n",
    "        _, test_label = torch.max(F.softmax(test_pred, dim=1), 1)\n",
    "\n",
    "        Test_GT.extend(np.array(test_gt.cpu()))\n",
    "        Test_label.extend(np.array(test_label.cpu()))\n",
    "        \n",
    "Test_GT, Test_label = np.array(Test_GT), np.array(Test_label)\n",
    "\n",
    "Test_OA    = metrics.accuracy_score(Test_GT,Test_label)\n",
    "Test_Kappa = metrics.cohen_kappa_score(Test_GT,Test_label)\n",
    "F1_score   = metrics.f1_score(Test_GT,Test_label)\n",
    "Precision  = metrics.precision_score(Test_GT,Test_label)\n",
    "Recall     = metrics.recall_score(Test_GT,Test_label)\n",
    "\n",
    "print('F1_socre: {:.2f}; OA: {:.2f}; Kappa: {:.4f}; Precision: {:.4f}; Recall: {:.4f}; '.format(F1_score*100, Test_OA*100, Test_Kappa, Precision, Recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate result picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 gain total samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_loader = gain_total_batch(Time1, Time2, GT, args.patches, args.batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 gain predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='DADSSFF_' + args.dataset + '.pth'\n",
    "model = torch.load(name)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    Total_pred, Total_position = [], []\n",
    "\n",
    "    for total_location, Total_T1, Total_T2,_ in Total_loader:\n",
    "        \n",
    "        Total_T1, Total_T2 = Total_T1.to(Device), Total_T2.to(Device)            \n",
    "        total_pred, _, _   = model(Total_T1, Total_T2)\n",
    "        \n",
    "        _, total_label = torch.max(F.softmax(total_pred, dim=1), 1)\n",
    "\n",
    "        Total_pred.extend(np.array(total_label.cpu()))\n",
    "        Total_position.extend(np.array(total_location.cpu()))\n",
    "\n",
    "Total_pred     = np.array(Total_pred)\n",
    "Total_position = np.array(Total_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Get result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = generate_png(GT, Total_position, Total_pred, args.dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
