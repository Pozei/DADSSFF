{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "from Model_DADSSFF import DADSSFF\n",
    "import torch.nn.functional as F \n",
    "from GeneratePic import generate_png\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn import metrics, preprocessing\n",
    "from Gain_batch import gain_train_test_batch, gain_total_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Hyerparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='CD-DADSSFF')\n",
    "parser.add_argument('--dataset',              default='River', help ='name   of datasets: China, River, USA')\n",
    "parser.add_argument('--patches',  type=int,   default=7,       help ='size   of patches')\n",
    "parser.add_argument('--batches',  type=int,   default=64,      help ='number of batches')\n",
    "parser.add_argument('--epoches',  type=int,   default=100,     help ='amount of epoches')\n",
    "parser.add_argument('--tr_rate',  type=float, default=5e-2,    help ='rate   of train')\n",
    "parser.add_argument('--lr_rate',  type=float, default=0.001,   help ='rate   of learning')\n",
    "parser.add_argument('--decay',    type=float, default=0.001,   help ='weight of decay ')\n",
    "parser.add_argument('--cuda',     type=int,   default=2,       help ='ID     of cuda ')\n",
    "parser.add_argument('--seed',     type=int,   default=1024,    help ='random seed ')\n",
    "\n",
    "parser.add_argument('--lambdas1', type=float, default=1.0,     help ='Hyperparameter of DA  loss')\n",
    "parser.add_argument('--lambdas2', type=float, default=1.0,     help ='Hyperparameter of KLD loss')\n",
    "\n",
    "args=parser.parse_args(args=[])\n",
    "\n",
    "Device = torch.device('cuda:' + str(args.cuda) if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'China':\n",
    "    T1 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/code/DADSSFF/data/01_China/China_T1.mat')['China_T1']\n",
    "    T2 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/code/DADSSFF/data/01_China/China_T2.mat')['China_T2']\n",
    "    GT = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/code/DADSSFF/data/01_China/China_GT.mat')['China_GT']\n",
    "elif args.dataset == 'River':\n",
    "    T1 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/02_River/River_T1.mat')['River_T1']\n",
    "    T2 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/02_River/River_T2.mat')['River_T2']\n",
    "    GT = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/02_River/River_GT.mat')['River_GT']\n",
    "elif args.dataset == 'USA':\n",
    "    T1 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_T1.mat')['USA_T1']\n",
    "    T2 = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_T2.mat')['USA_T2']\n",
    "    GT = sio.loadmat('/home/qinxuexiang/01_ChangeDetection/data/03_USA/USA_GT.mat')['USA_GT']\n",
    "else:\n",
    "    print(\"Please enter one of 'China', 'River' and 'USA'!\")\n",
    "\n",
    "H1, W1, B1=T1.shape\n",
    "H2, W2, B2=T2.shape\n",
    "TT1=T1.reshape(H1*W1, B1)\n",
    "TT2=T2.reshape(H2*W2, B2)\n",
    "T1=preprocessing.scale(TT1)\n",
    "T2=preprocessing.scale(TT2)\n",
    "Time1=T1.reshape(H1, W1, B1)\n",
    "Time2=T2.reshape(H2, W2, B2)\n",
    "classes_num=np.max(GT)+1\n",
    "print(\"Time1 shape: \", Time1.shape)\n",
    "print(\"Time2 shape: \", Time2.shape)\n",
    "print('class_num:',    classes_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Selecting Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_loader, Test_loader = gain_train_test_batch(Time1, Time2, GT, args.tr_rate, args.patches, args.batches, args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DADSSFF(bands=B1, num_classes=classes_num).to(Device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr_rate, weight_decay=args.decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0\n",
    "for epoch in range(args.epoches):\n",
    "    model.train()\n",
    "    Train_Loss, Train_GT, Train_label= [], [], []\n",
    "\n",
    "    for train_T1, train_T2, train_gt in Train_loader:\n",
    "\n",
    "        train_T1, train_T2, train_gt = train_T1.to(Device), train_T2.to(Device), train_gt.to(Device)\n",
    "\n",
    "        ## 1) Forwards\n",
    "        train_pred, train_DA_loss, train_KLD_loss = model(train_T1, train_T2)\n",
    "        loss = criterion(train_pred, train_gt) + args.lambdas1*train_DA_loss + args.lambdas2*train_KLD_loss\n",
    "\n",
    "        ## 2) Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ## 3) Backward and update weights\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        ## 4) estimate accuracy\n",
    "        _, train_label = torch.max(F.softmax(train_pred, dim=1), 1)\n",
    "\n",
    "        Train_Loss.append(loss.cpu().item())\n",
    "        Train_GT.extend(np.array(train_gt.cpu()))\n",
    "        Train_label.extend(np.array(train_label.cpu()))\n",
    "\n",
    "    Train_Loss = np.array(Train_Loss)\n",
    "    Train_GT   = np.array(Train_GT)\n",
    "    Train_label= np.array(Train_label)\n",
    "    Train_F1   = metrics.f1_score(Train_GT, Train_label)\n",
    "\n",
    "    ## Test\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        model.eval()    \n",
    "        with torch.no_grad():\n",
    "\n",
    "            Test_loss, Test_GT, Test_label = [], [], []\n",
    "                      \n",
    "            for test_T1, test_T2, test_gt in Test_loader:\n",
    "\n",
    "                test_T1, test_T2, test_gt = test_T1.to(Device), test_T2.to(Device), test_gt.to(Device)\n",
    "\n",
    "                test_pred, test_DA_loss, test_KLD_loss = model(test_T1, test_T2) \n",
    "                test_loss = criterion(test_pred, test_gt) + args.lambdas1*test_DA_loss + args.lambdas2*test_KLD_loss\n",
    "\n",
    "                _, test_label = torch.max(F.softmax(test_pred, dim=1), 1)\n",
    "\n",
    "                Test_loss.append(test_loss.cpu().item())\n",
    "                Test_GT.extend(np.array(test_gt.cpu()))\n",
    "                Test_label.extend(np.array(test_label.cpu()))\n",
    "\n",
    "        Test_loss = np.array(Test_loss)\n",
    "        Test_GT   = np.array(Test_GT)\n",
    "        Test_label= np.array(Test_label)\n",
    "        Test_F1   = metrics.f1_score(Test_GT,Test_label)\n",
    "\n",
    "        print('epoch: {:03d}/{}; Train loss: {:.4f}; Train F1: {:.4f}; // Test loss:{:.4f}; Test F1: {:.4f}'.format\\\n",
    "              (epoch+1, args.epoches, np.mean(Train_Loss), Train_F1*100, np.mean(Test_loss), Test_F1*100))\n",
    "\n",
    "        if Test_F1 >= best:\n",
    "            best = Test_F1\n",
    "            name='DADSSFF_' + args.dataset + '.pth'\n",
    "            torch.save(model, name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='DADSSFF_' + args.dataset + '.pth'\n",
    "model = torch.load(name)\n",
    "model.eval()    \n",
    "with torch.no_grad():\n",
    "\n",
    "    Test_GT, Test_label = [], []\n",
    "                      \n",
    "    for test_T1, test_T2, test_gt in Test_loader:\n",
    "\n",
    "        test_T1, test_T2, test_gt = test_T1.to(Device), test_T2.to(Device), test_gt.to(Device)\n",
    "\n",
    "        test_pred, _, _ = model(test_T1, test_T2)        \n",
    "\n",
    "        _, test_label = torch.max(F.softmax(test_pred, dim=1), 1)\n",
    "\n",
    "        Test_GT.extend(np.array(test_gt.cpu()))\n",
    "        Test_label.extend(np.array(test_label.cpu()))\n",
    "        \n",
    "Test_GT, Test_label = np.array(Test_GT), np.array(Test_label)\n",
    "\n",
    "Test_OA    = metrics.accuracy_score(Test_GT,Test_label)\n",
    "Test_Kappa = metrics.cohen_kappa_score(Test_GT,Test_label)\n",
    "F1_score   = metrics.f1_score(Test_GT,Test_label)\n",
    "Precision  = metrics.precision_score(Test_GT,Test_label)\n",
    "Recall     = metrics.recall_score(Test_GT,Test_label)\n",
    "\n",
    "print('F1_socre: {:.2f}; OA: {:.2f}; Kappa: {:.4f}; Precision: {:.4f}; Recall: {:.4f}; '.format(F1_score*100, Test_OA*100, Test_Kappa, Precision, Recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate result picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 gain total samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_loader = gain_total_batch(Time1, Time2, GT, args.patches, args.batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 gain predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(name)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    Total_pred, Total_position = [], []\n",
    "\n",
    "    for total_location, Total_T1, Total_T2,_ in Total_loader:\n",
    "        \n",
    "        Total_T1, Total_T2 = Total_T1.to(Device), Total_T2.to(Device)            \n",
    "        total_pred, _, _   = model(Total_T1, Total_T2)\n",
    "        \n",
    "        _, total_label = torch.max(F.softmax(total_pred, dim=1), 1)\n",
    "\n",
    "        Total_pred.extend(np.array(total_label.cpu()))\n",
    "        Total_position.extend(np.array(total_location.cpu()))\n",
    "\n",
    "Total_pred     = np.array(Total_pred)\n",
    "Total_position = np.array(Total_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Get result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = generate_png(GT, Total_position, Total_pred, args.dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
